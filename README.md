### Leveraging neural networks and edge detection for better UAV localization ðŸšðŸ—ºï¸ðŸ“
Official implementation for the paper "Leveraging neural networks and edge detection for better UAV localization".

Paper accepted to IGARSS 2024 : [arXiv submission](https://arxiv.org/abs/2404.06207)

> [!WARNING]  
> Code is still in development.

## Method Overview

Offline, the edges of the RGB reference images are extracted to generate single-channel images. An AutoEncoder is then trained on these images for a task of pixel-by-pixel reconstruction. Subsequently, positions, embeddings, and the frozen encoder are transferred onto the drone.

Online, the drone's view is captured through a camera positioned beneath it. The outlines of the RGB image are then extracted and forwarded to the encoder, which generates an embedding. This embedding is subsequently compared, using cosine similarity, to all embeddings derived from the reference images. The drone's position is then inferred based on the position of the reference image with the highest similarity score.

<img src="https://github.com/theodpzz/uav-localization/blob/main/figures/overview_method_final.png" alt="Method overview" width="600">

## Getting Started

> [!TIP]
> This section outlines the main steps to discover the code.

### Clone the Repository

To clone this repository, use the following command:

```bash
git clone https://github.com/TheoDpPro/uav-localization.git
```

### Installation

Make sure you have Python 3 installed. Then, install the dependencies using:

```bash
pip install -r requirements.txt
```

### Training

To train the model, run the following command:

```bash
python train.py
```

### Data

Example data is available in example-data folder.

> [!WARNING]  
> These are toy examples and do not correspond to the dataset used.

train.csv, test.csv contain filenames and coordinates of each tile.
Below the structure of the data folder for n reference tiles and m uav views.

```bash
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ reference_tile_1.npy
â”‚   â”œâ”€â”€ reference_tile_2.npy
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ reference_tile_n.npy
â”‚
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ uav_view_1.npy
â”‚   â”œâ”€â”€ uav_view_2.npy
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ uav_view_m.npy
â”‚
â”œâ”€â”€ train.csv
â””â”€â”€ test.csv
```

## Acknowledgment

Thanks to ABGRALL Corentin, BASCLE Benedicte, DAVAUX Jean-ClÃ©ment, FACCIOLO Gabriele and MEINHARDT-LLOPIS Enric.

## Citation

> [!IMPORTANT]  
> This project is based on the work by Di Piazza et al. If you use this code in your research, please cite the following paper:

```BibTeX
@inproceedings{dipiazza2024uavloc,
  author    = {Di Piazza Theo, Meinhardt-Llopis Enric, Facciolo Gabriele, Bascle Benedicte, Abgrall Corentin and Devaux Jean-Clement},
  title     = {Leveraging neural networks and edge detection for better UAV localization},
  booktitle = {Proceedings of the IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  year      = {2024},
  organization = {IEEE},
}
```
